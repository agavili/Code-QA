{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd69ab7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain>=0.0.218 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain[llms]>=0.0.218) (0.0.284)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain>=0.0.218->langchain[llms]>=0.0.218) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain>=0.0.218->langchain[llms]>=0.0.218) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain>=0.0.218->langchain[llms]>=0.0.218) (3.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain>=0.0.218->langchain[llms]>=0.0.218) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain>=0.0.218->langchain[llms]>=0.0.218) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain>=0.0.218->langchain[llms]>=0.0.218) (0.0.69)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain>=0.0.218->langchain[llms]>=0.0.218) (2.8.8)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain>=0.0.218->langchain[llms]>=0.0.218) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain>=0.0.218->langchain[llms]>=0.0.218) (1.10.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain>=0.0.218->langchain[llms]>=0.0.218) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain>=0.0.218->langchain[llms]>=0.0.218) (8.1.0)\n",
      "Collecting clarifai>=9.1.0 (from langchain[llms]>=0.0.218)\n",
      "  Downloading clarifai-10.2.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cohere<5,>=4 (from langchain[llms]>=0.0.218)\n",
      "  Downloading cohere-4.57-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: huggingface_hub<1,>=0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain[llms]>=0.0.218) (0.11.1)\n",
      "Collecting manifest-ml<0.0.2,>=0.0.1 (from langchain[llms]>=0.0.218)\n",
      "  Downloading manifest_ml-0.0.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting nlpcloud<2,>=1 (from langchain[llms]>=0.0.218)\n",
      "  Downloading nlpcloud-1.1.46-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: openai<1,>=0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain[llms]>=0.0.218) (0.28.0)\n",
      "Collecting openlm<0.0.6,>=0.0.5 (from langchain[llms]>=0.0.218)\n",
      "  Downloading openlm-0.0.5-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: torch<3,>=1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain[llms]>=0.0.218) (1.13.1)\n",
      "Requirement already satisfied: transformers<5,>=4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchain[llms]>=0.0.218) (4.25.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->langchain[llms]>=0.0.218) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->langchain[llms]>=0.0.218) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->langchain[llms]>=0.0.218) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->langchain[llms]>=0.0.218) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.218->langchain[llms]>=0.0.218) (1.3.1)\n",
      "Collecting clarifai-grpc~=10.2.1 (from clarifai>=9.1.0->langchain[llms]>=0.0.218)\n",
      "  Downloading clarifai_grpc-10.2.3-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.65.0 (from clarifai>=9.1.0->langchain[llms]>=0.0.218)\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tritonclient>=2.34.0 (from clarifai>=9.1.0->langchain[llms]>=0.0.218)\n",
      "  Downloading tritonclient-2.44.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rich>=13.4.2 (from clarifai>=9.1.0->langchain[llms]>=0.0.218)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain>=0.0.218->langchain[llms]>=0.0.218)\n",
      "  Downloading PyYAML-6.0.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting schema>=0.7.5 (from clarifai>=9.1.0->langchain[llms]>=0.0.218)\n",
      "  Downloading schema-0.7.5-py2.py3-none-any.whl.metadata (34 kB)\n",
      "Collecting Pillow>=9.5.0 (from clarifai>=9.1.0->langchain[llms]>=0.0.218)\n",
      "  Downloading pillow-10.3.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting inquirerpy==0.3.4 (from clarifai>=9.1.0->langchain[llms]>=0.0.218)\n",
      "  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: tabulate>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from clarifai>=9.1.0->langchain[llms]>=0.0.218) (0.9.0)\n",
      "Collecting pfzy<0.4.0,>=0.3.1 (from inquirerpy==0.3.4->clarifai>=9.1.0->langchain[llms]>=0.0.218)\n",
      "  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from inquirerpy==0.3.4->clarifai>=9.1.0->langchain[llms]>=0.0.218) (3.0.31)\n",
      "Requirement already satisfied: backoff<3.0,>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cohere<5,>=4->langchain[llms]>=0.0.218) (2.2.1)\n",
      "Collecting fastavro<2.0,>=1.8 (from cohere<5,>=4->langchain[llms]>=0.0.218)\n",
      "  Downloading fastavro-1.9.4.tar.gz (985 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m985.9/985.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib_metadata<7.0,>=6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cohere<5,>=4->langchain[llms]>=0.0.218) (6.0.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from cohere<5,>=4->langchain[llms]>=0.0.218) (2.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.218->langchain[llms]>=0.0.218) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.218->langchain[llms]>=0.0.218) (0.9.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub<1,>=0->langchain[llms]>=0.0.218) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub<1,>=0->langchain[llms]>=0.0.218) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface_hub<1,>=0->langchain[llms]>=0.0.218) (21.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dill>=0.3.5 (from manifest-ml<0.0.2,>=0.0.1->langchain[llms]>=0.0.218)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting redis>=4.3.1 (from manifest-ml<0.0.2,>=0.0.1->langchain[llms]>=0.0.218)\n",
      "  Downloading redis-5.0.3-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting sqlitedict>=2.0.0 (from manifest-ml<0.0.2,>=0.0.1->langchain[llms]>=0.0.218)\n",
      "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain>=0.0.218->langchain[llms]>=0.0.218) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain>=0.0.218->langchain[llms]>=0.0.218) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchain>=0.0.218->langchain[llms]>=0.0.218) (2023.11.17)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5,>=4->langchain[llms]>=0.0.218) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5,>=4->langchain[llms]>=0.0.218) (0.13.2)\n",
      "Requirement already satisfied: grpcio>=1.44.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from clarifai-grpc~=10.2.1->clarifai>=9.1.0->langchain[llms]>=0.0.218) (1.49.1)\n",
      "Requirement already satisfied: protobuf>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from clarifai-grpc~=10.2.1->clarifai>=9.1.0->langchain[llms]>=0.0.218) (3.20.3)\n",
      "Collecting googleapis-common-protos>=1.53.0 (from clarifai-grpc~=10.2.1->clarifai>=9.1.0->langchain[llms]>=0.0.218)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from importlib_metadata<7.0,>=6.0->cohere<5,>=4->langchain[llms]>=0.0.218) (3.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub<1,>=0->langchain[llms]>=0.0.218) (3.0.9)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13.4.2->clarifai>=9.1.0->langchain[llms]>=0.0.218)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from rich>=13.4.2->clarifai>=9.1.0->langchain[llms]>=0.0.218) (2.13.0)\n",
      "Collecting contextlib2>=0.5.5 (from schema>=0.7.5->clarifai>=9.1.0->langchain[llms]>=0.0.218)\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting python-rapidjson>=0.9.1 (from tritonclient>=2.34.0->clarifai>=9.1.0->langchain[llms]>=0.0.218)\n",
      "  Downloading python_rapidjson-1.16-cp310-cp310-macosx_11_0_arm64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.218->langchain[llms]>=0.0.218) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from grpcio>=1.44.0->clarifai-grpc~=10.2.1->clarifai>=9.1.0->langchain[llms]>=0.0.218) (1.16.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.4.2->clarifai>=9.1.0->langchain[llms]>=0.0.218)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: wcwidth in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from prompt-toolkit<4.0.0,>=3.0.1->inquirerpy==0.3.4->clarifai>=9.1.0->langchain[llms]>=0.0.218) (0.2.5)\n",
      "Downloading clarifai-10.2.1-py3-none-any.whl (164 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.0/164.0 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cohere-4.57-py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.9/52.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading manifest_ml-0.0.1-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nlpcloud-1.1.46-py3-none-any.whl (3.9 kB)\n",
      "Downloading openlm-0.0.5-py3-none-any.whl (10 kB)\n",
      "Downloading PyYAML-6.0.1-cp310-cp310-macosx_11_0_arm64.whl (169 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.3/169.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading clarifai_grpc-10.2.3-py3-none-any.whl (237 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.9/237.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.3.0-cp310-cp310-macosx_11_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading redis-5.0.3-py3-none-any.whl (251 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.8/251.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
      "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tritonclient-2.44.0-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
      "Downloading python_rapidjson-1.16-cp310-cp310-macosx_11_0_arm64.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: fastavro, sqlitedict\n",
      "  Building wheel for fastavro (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fastavro: filename=fastavro-1.9.4-cp310-cp310-macosx_10_9_universal2.whl size=1092617 sha256=cc4f02d8150322ec20a900868e54c2cf2d5c80d3432caab2e69602cfaf9467f9\n",
      "  Stored in directory: /Users/aishwaryagavili/Library/Caches/pip/wheels/f5/cc/c3/8d2ab49631057f55a6512033e2c58145f81a8c49508f45e839\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=a936b9d4a29de4e5fd3d95d9ba79bdb58dbeffc2947b8c0c57f46a0fa4147811\n",
      "  Stored in directory: /Users/aishwaryagavili/Library/Caches/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
      "Successfully built fastavro sqlitedict\n",
      "Installing collected packages: sqlitedict, tqdm, redis, PyYAML, python-rapidjson, Pillow, pfzy, mdurl, googleapis-common-protos, fastavro, dill, contextlib2, tritonclient, schema, openlm, nlpcloud, markdown-it-py, manifest-ml, inquirerpy, clarifai-grpc, rich, cohere, clarifai\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.64.1\n",
      "    Uninstalling tqdm-4.64.1:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Successfully uninstalled tqdm-4.64.1\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 9.2.0\n",
      "    Uninstalling Pillow-9.2.0:\n",
      "      Successfully uninstalled Pillow-9.2.0\n",
      "  Attempting uninstall: rich\n",
      "    Found existing installation: rich 13.1.0\n",
      "    Uninstalling rich-13.1.0:\n",
      "      Successfully uninstalled rich-13.1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyppeteer 1.0.2 requires urllib3<2.0.0,>=1.25.8, but you have urllib3 2.1.0 which is incompatible.\n",
      "pyppeteer 1.0.2 requires websockets<11.0,>=10.0, but you have websockets 12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Pillow-10.3.0 PyYAML-6.0.1 clarifai-10.2.1 clarifai-grpc-10.2.3 cohere-4.57 contextlib2-21.6.0 dill-0.3.8 fastavro-1.9.4 googleapis-common-protos-1.63.0 inquirerpy-0.3.4 manifest-ml-0.0.1 markdown-it-py-3.0.0 mdurl-0.1.2 nlpcloud-1.1.46 openlm-0.0.5 pfzy-0.3.4 python-rapidjson-1.16 redis-5.0.3 rich-13.7.1 schema-0.7.5 sqlitedict-2.1.0 tqdm-4.66.2 tritonclient-2.44.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: requests>=2.28 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from chromadb) (1.10.2)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (252 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Downloading fastapi-0.110.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from chromadb) (1.23.5)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from chromadb) (4.9.0)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
      "  Downloading pulsar_client-3.4.0-cp310-cp310-macosx_10_15_universal2.whl.metadata (1.0 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.17.1-cp310-cp310-macosx_11_0_universal2.whl.metadata (4.2 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from chromadb) (0.13.2)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from chromadb) (4.66.2)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.62.1-cp310-cp310-macosx_12_0_universal2.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.1.2-cp39-abi3-macosx_10_12_universal2.whl.metadata (9.5 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.12.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting tenacity>=8.2.3 (from chromadb)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from chromadb) (6.0.1)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-4.1.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb)\n",
      "  Downloading orjson-3.10.0-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=19.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (21.3)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.0.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting tomli>=1.1.0 (from build>=1.0.3->chromadb)\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting starlette<0.37.0,>=0.36.3 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading starlette-0.36.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2023.11.17)\n",
      "Requirement already satisfied: six>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.22.0)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading websocket_client-1.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: requests-oauthlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.1.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading sympy-1.12-py3-none-any.whl.metadata (12 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: importlib-metadata<=7.0,>=6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (63.2.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.28->chromadb) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.4)\n",
      "Collecting typer-slim==0.12.0 (from typer-slim[standard]==0.12.0->typer>=0.9.0->chromadb)\n",
      "  Downloading typer_slim-0.12.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting typer-cli==0.12.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading typer_cli-0.12.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer-slim==0.12.0->typer-slim[standard]==0.12.0->typer>=0.9.0->chromadb) (8.1.3)\n",
      "Collecting shellingham>=1.3.0 (from typer-slim[standard]==0.12.0->typer>=0.9.0->chromadb)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer-slim[standard]==0.12.0->typer>=0.9.0->chromadb) (13.7.1)\n",
      "Requirement already satisfied: h11>=0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.13.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.19.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-0.21.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Collecting urllib3>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from packaging>=19.1->build>=1.0.3->chromadb) (3.0.9)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (3.7.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from rich>=10.11.0->typer-slim[standard]==0.12.0->typer>=0.9.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from rich>=10.11.0->typer-slim[standard]==0.12.0->typer>=0.9.0->chromadb) (2.13.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer-slim[standard]==0.12.0->typer>=0.9.0->chromadb) (0.1.2)\n",
      "Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-macosx_11_0_arm64.whl (197 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.1/197.1 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.1.2-cp39-abi3-macosx_10_12_universal2.whl (528 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.5/528.5 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.62.1-cp310-cp310-macosx_12_0_universal2.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-4.1.0-cp310-cp310-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading onnxruntime-1.17.1-cp310-cp310-macosx_11_0_universal2.whl (14.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
      "Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.0-cp310-cp310-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (252 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.1/252.1 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pulsar_client-3.4.0-cp310-cp310-macosx_10_15_universal2.whl (10.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading typer-0.12.0-py3-none-any.whl (5.6 kB)\n",
      "Downloading typer_cli-0.12.0-py3-none-any.whl (3.0 kB)\n",
      "Downloading typer_slim-0.12.0-py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading httptools-0.6.1-cp310-cp310-macosx_10_9_universal2.whl (149 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.8/149.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.19.0-cp310-cp310-macosx_10_9_universal2.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.21.0-cp310-cp310-macosx_11_0_arm64.whl (418 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.3/418.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websocket_client-1.7.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=e6f7d2b51c9db19902be8b569c607acbea7164e794abe293f0dec4352ec5e965\n",
      "  Stored in directory: /Users/aishwaryagavili/Library/Caches/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, mpmath, monotonic, mmh3, websocket-client, uvloop, uvicorn, urllib3, typer-slim, tomli, tenacity, sympy, shellingham, pulsar-client, overrides, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, importlib-resources, humanfriendly, httptools, grpcio, deprecated, chroma-hnswlib, bcrypt, asgiref, watchfiles, starlette, pyproject_hooks, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, posthog, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, fastapi, build, typer-cli, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, kubernetes, typer, opentelemetry-instrumentation-fastapi, chromadb\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.1.0\n",
      "    Uninstalling urllib3-2.1.0:\n",
      "      Successfully uninstalled urllib3-2.1.0\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.1.0\n",
      "    Uninstalling tenacity-8.1.0:\n",
      "      Successfully uninstalled tenacity-8.1.0\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.49.1\n",
      "    Uninstalling grpcio-1.49.1:\n",
      "      Successfully uninstalled grpcio-1.49.1\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.7.0\n",
      "    Uninstalling typer-0.7.0:\n",
      "      Successfully uninstalled typer-0.7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyppeteer 1.0.2 requires websockets<11.0,>=10.0, but you have websockets 12.0 which is incompatible.\n",
      "scikeras 0.11.0 requires grpcio<1.50.0; python_version >= \"3.10\" and sys_platform == \"darwin\", but you have grpcio 1.62.1 which is incompatible.\n",
      "spacy 3.4.4 requires typer<0.8.0,>=0.3.0, but you have typer 0.12.0 which is incompatible.\n",
      "tritonclient 2.44.0 requires urllib3>=2.0.7, but you have urllib3 1.26.18 which is incompatible.\u001b[0m\u001b[31m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mSuccessfully installed asgiref-3.8.1 bcrypt-4.1.2 build-1.2.1 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.110.0 grpcio-1.62.1 httptools-0.6.1 humanfriendly-10.0 importlib-resources-6.4.0 kubernetes-29.0.0 mmh3-4.1.0 monotonic-1.6 mpmath-1.3.0 onnxruntime-1.17.1 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 orjson-3.10.0 overrides-7.7.0 posthog-3.5.0 pulsar-client-3.4.0 pypika-0.48.9 pyproject_hooks-1.0.0 shellingham-1.5.4 starlette-0.36.3 sympy-1.12 tenacity-8.2.3 tomli-2.0.1 typer-0.12.0 typer-cli-0.12.0 typer-slim-0.12.0 urllib3-1.26.18 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websocket-client-1.7.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: sentence_transformers in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence_transformers) (4.25.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence_transformers) (4.66.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence_transformers) (0.14.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence_transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence_transformers) (1.11.2)\n",
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence_transformers) (3.8)\n",
      "Requirement already satisfied: sentencepiece in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence_transformers) (0.1.97)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence_transformers) (0.11.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.8.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.2)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torchvision->sentence_transformers) (10.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.11.17)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tiktoken in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tiktoken) (2022.10.31)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: GitPython in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.1.30)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from GitPython) (4.0.10)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython) (5.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install \"langchain[llms]>=0.0.218\"\n",
    "!pip3 install chromadb\n",
    "!pip3 install sentence_transformers\n",
    "!pip3 install tiktoken\n",
    "!pip3 install GitPython\n",
    "!pip3 install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227cec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import LanguageParser\n",
    "from langchain_text_splitters import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd494d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c52f54db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e05228ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d32f3602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "283e4691",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = \"https://github.com/agavili/skincare-recommender\"\n",
    "local_repo_location = \"test_repo_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "220620d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "repo = Repo.clone_from(repo_path, to_path=os.path.join(os.getcwd(),local_repo_location))\n",
    "# repo = Repo.clone_from(\n",
    "#     \"https://github.com/langchain-ai/langchain\", to_path=\"/tmp/test_repo\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "629bb397",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GenericLoader.from_filesystem(\n",
    "    os.path.join(os.getcwd(), local_repo_location) + \"/app\",\n",
    "    glob=\"**/*\",\n",
    "    suffixes=[\".py\"],\n",
    "    parser=LanguageParser(language=Language.PYTHON, parser_threshold=500)\n",
    ")\n",
    "documents = loader.load()\n",
    "# len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f39bc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c959346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"from pyforest import *\\nfrom sentence_transformers import SentenceTransformer\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nfrom sklearn.metrics.pairwise import cosine_similarity\\n\\n# Description Embedders\\ndef embed_description(df):\\n    X = np.array(df.product_description)\\n    text_data = X\\n    model = SentenceTransformer('distilbert-base-nli-mean-tokens')\\n    embeddings = model.encode(text_data, show_progress_bar=True)\\n    embed_data = embeddings\\n    X = np.array(embed_data)\\n    return pd.DataFrame(cosine_similarity(X))\\n\\n\\n# Create Recommender \\ndef recommender(search, df, ingred=False, description=False, product_count = 5):\\n    if(ingred):\\n        myItem = df[df.name == search]\\n        myItem.reset_index(drop=True, inplace=True)\\n        P1 = np.array([myItem.X.values, myItem.Y.values]).reshape(1, -1)\\n        cos_sim = []\\n        for i in range(len(df)):\\n            P2 = np.array([df['X'][i], df['Y'][i]]).reshape(-1, 1)\\n            cos_sim.append((np.dot(P1, P2)/(np.linalg.norm(P1)*np.linalg.norm(P2)))[0][0])\\n        \\n        index_recomm = pd.DataFrame(cos_sim, columns=['cosine_sim']).sort_values(by=['cosine_sim'],ascending=False).index.tolist()\\n        products_recomm =  df.loc[index_recomm]\\n                \\n    elif(description):\\n        cos_sim = embed_description(df)\\n        index = df.index[df['name'] == search][0]\\n        index_recomm = cos_sim.loc[index].sort_values(ascending=False).index.tolist()\\n        products_recomm =  df.loc[index_recomm]\\n        \\n    products_recomm = products_recomm[(products_recomm.name != search)]\\n\\n    return products_recomm.head(product_count)\\n\\n\\n\", metadata={'source': '/Users/aishwaryagavili/Desktop/genai-projs/rag-python-proj/test_repo_3/app/recommendation_engine.py', 'language': <Language.PYTHON: 'python'>})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "652310fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=2000, chunk_overlap=200\n",
    ")\n",
    "texts = python_splitter.split_documents(documents)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd84733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "db = Chroma.from_documents(texts, OpenAIEmbeddings(disallowed_special=()))\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\",  # Also test \"similarity\"\n",
    "    search_kwargs={\"k\": 8},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f8ae283",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtexts\u001b[49m[\u001b[38;5;241m3\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'texts' is not defined"
     ]
    }
   ],
   "source": [
    "texts[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc9e73",
   "metadata": {},
   "source": [
    "# LLM Integration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b4f997ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\")\n",
    "memory = ConversationSummaryMemory(\n",
    "    llm=llm, memory_key=\"chat_history\", return_messages=True\n",
    ")\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0b26a0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, the code uses TruncatedSVD in the function svd_tsne to reduce the feature dimensionality of the ingredient matrix.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Is TruncatedSVD being used in the code?\"\n",
    "result = qa(question)\n",
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "088475a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> **Question**: What is the class hierarchy? \n",
      "\n",
      "**Answer**: The ReAct agent is represented by the ReActDocstoreAgent class which is a type of Agent. Here is the hierarchy of classes related to the ReActDocstoreAgent:\n",
      "\n",
      "1. BaseTool: This is a base class for the tools that the agent can use. \n",
      "\n",
      "2. BasePromptTemplate: This is a base class for creating prompts. The method `create_prompt` in ReActDocstoreAgent uses this to return the default prompt.\n",
      "\n",
      "3. BaseSingleActionAgent, OpenAIMultiFunctionsAgent: These classes are types of agents and are part of the dictionary `AGENT_TO_CLASS`.\n",
      "\n",
      "4. ReActDocstoreAgent: This is the main class for the ReAct agent. It has methods for getting the default output parser, validating the tools, creating a prompt, and other properties related to the agent's operation. It also defines the type of the agent as `REACT_DOCSTORE`. This class is part of the `AGENT_TO_CLASS` dictionary with the key `AgentType.REACT_DOCSTORE`.\n",
      "\n",
      "5. AgentOutputParser: This is a base class for parsing the output of the agent. The ReActDocstoreAgent uses a specific output parser `ReActOutputParser`.\n",
      "\n",
      "6. AgentExecutor: This class is used to execute the agent's actions.\n",
      "\n",
      "The above classes are used in initializing and executing a ReAct agent's actions. Also, the ReActDocstoreAgent class uses other classes like BaseTool for tools, AgentOutputParser for parsing output, and others for various operations. \n",
      "\n",
      "-> **Question**: What classes are derived from the Chain class? \n",
      "\n",
      "**Answer**: The classes derived from the Chain class are:\n",
      "\n",
      "- BaseConversationalRetrievalChain\n",
      "- MultiRouteChain\n",
      "- RouterChain\n",
      "- MultiPromptChain\n",
      "- MultiRetrievalQAChain\n",
      "- LLMRouterChain\n",
      "- TrajectoryEvalChain\n",
      "- LabeledPairwiseStringEvalChain\n",
      "- PairwiseStringEvalChain\n",
      "- CriteriaEvalChain\n",
      "- LabeledCriteriaEvalChain\n",
      "- EmbeddingDistanceEvalChain\n",
      "- PairwiseEmbeddingDistanceEvalChain\n",
      "- ContextQAEvalChain\n",
      "- CotQAEvalChain\n",
      "- QAEvalChain\n",
      "- LabeledScoreStringEvalChain\n",
      "- ScoreStringEvalChain\n",
      "- PairwiseStringDistanceEvalChain\n",
      "- StringDistanceEvalChain\n",
      "\n",
      "And any class that starts with <name>Chain in the class hierarchy (for example, LLMChain, MapReduceChain, RouterChain) is also derived from the Chain class. \n",
      "\n",
      "-> **Question**: What one improvement do you propose in code in relation to the class hierarchy for the Chain class? \n",
      "\n",
      "**Answer**: The class hierarchy of the Chain class isn't clearly defined in the code. It would be beneficial to have a more explicit and structured hierarchy, perhaps through the use of subclasses and inheritance. This could make it easier to understand the relationships between different chains and their functionalities, and could also reduce code redundancy if common features are implemented in a parent class. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"What is the class hierarchy?\",\n",
    "    \"What classes are derived from the Chain class?\",\n",
    "    \"What one improvement do you propose in code in relation to the class hierarchy for the Chain class?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    result = qa(question)\n",
    "    print(f\"-> **Question**: {question} \\n\")\n",
    "    print(f\"**Answer**: {result['answer']} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "40669131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import LlamaCpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b4dd6c1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 20 key-value pairs and 363 tensors from /Users/aishwaryagavili/Downloads/codellama-13b-instruct.Q4_K_S.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = codellama_codellama-13b-instruct-hf\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 16384\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 14\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32016]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32016]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32016]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q4_K:  273 tensors\n",
      "llama_model_loader: - type q5_K:    8 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: mismatch in special tokens definition ( 264/32016 vs 259/32016 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32016\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 16384\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 16384\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Small\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 6.90 GiB (4.56 BPW) \n",
      "llm_load_print_meta: general.name     = codellama_codellama-13b-instruct-hf\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.28 MiB\n",
      "ggml_backend_metal_buffer_from_ptr: allocated buffer, size =   170.20 MiB, (  837.73 / 10922.67)\n",
      "llm_load_tensors: offloading 1 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 1/41 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  7070.25 MiB\n",
      "llm_load_tensors:      Metal buffer size =   170.20 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 5024\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M2\n",
      "ggml_metal_init: picking default device: Apple M2\n",
      "ggml_metal_init: using embedded metal library\n",
      "ggml_metal_init: GPU name:   Apple M2\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple8  (1008)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: simdgroup reduction support   = true\n",
      "ggml_metal_init: simdgroup matrix mul. support = true\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "llama_kv_cache_init:        CPU KV buffer size =  3826.88 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =    98.12 MiB, (  936.67 / 10922.67)\n",
      "llama_kv_cache_init:      Metal KV buffer size =    98.12 MiB\n",
      "llama_new_context_with_model: KV self size  = 3925.00 MiB, K (f16): 1962.50 MiB, V (f16): 1962.50 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =   442.33 MiB, ( 1379.00 / 10922.67)\n",
      "llama_new_context_with_model:      Metal compute buffer size =   442.32 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   442.32 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1286\n",
      "llama_new_context_with_model: graph splits = 3\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '40', 'llama.context_length': '16384', 'llama.attention.head_count': '40', 'llama.rope.freq_base': '1000000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '14', 'llama.feed_forward_length': '13824', 'llama.embedding_length': '5120', 'llama.block_count': '40', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'codellama_codellama-13b-instruct-hf'}\n",
      "Using fallback chat format: None\n",
      "ggml_metal_free: deallocating\n"
     ]
    }
   ],
   "source": [
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"/Users/aishwaryagavili/Downloads/codellama-13b-instruct.Q4_K_S.gguf\",\n",
    "    n_ctx=5000,\n",
    "    n_gpu_layers=1,\n",
    "    n_batch=512,\n",
    "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "34937926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6241b7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001a\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   18207.92 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     5 runs   (    0.17 ms per token,  5714.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18207.78 ms /    29 tokens (  627.85 ms per token,     1.59 tokens per second)\n",
      "llama_print_timings:        eval time =   45203.08 ms /     4 runs   (11300.77 ms per token,     0.09 tokens per second)\n",
      "llama_print_timings:       total time =   63447.37 ms /    33 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\x1a\\n\\n\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\n",
    "    \"Question: In bash, how do I list all the text files in the current directory that have been modified in the last month? Answer:\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f2bbf0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.15-py3-none-any.whl.metadata (621 bytes)\n",
      "Requirement already satisfied: requests<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from langchainhub) (2.31.0)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Downloading types_requests-2.31.0.20240403-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2->langchainhub) (2023.11.17)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchainhub)\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Downloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
      "Downloading types_requests-2.31.0.20240403-py3-none-any.whl (15 kB)\n",
      "Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, types-requests, langchainhub\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.18\n",
      "    Uninstalling urllib3-1.26.18:\n",
      "      Successfully uninstalled urllib3-1.26.18\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-auth 2.22.0 requires urllib3<2.0, but you have urllib3 2.2.1 which is incompatible.\n",
      "pyppeteer 1.0.2 requires urllib3<2.0.0,>=1.25.8, but you have urllib3 2.2.1 which is incompatible.\n",
      "pyppeteer 1.0.2 requires websockets<11.0,>=10.0, but you have websockets 12.0 which is incompatible.\n",
      "selenium 4.4.3 requires urllib3[socks]~=1.26, but you have urllib3 2.2.1 which is incompatible.\n",
      "spacy 3.4.4 requires typer<0.8.0,>=0.3.0, but you have typer 0.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchainhub-0.1.15 types-requests-2.31.0.20240403 urllib3-2.2.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "31f58dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import hub\n",
    "\n",
    "# QA_CHAIN_PROMPT = hub.pull(\"rlm/rag-prompt-default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc9977ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from pyforest import *\\nfrom sentence_transformers import SentenceTransformer\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nfrom sklearn.metrics.pairwise import cosine_similarity\\n\\n# Description Embedders\\ndef embed_description(df):\\n    X = np.array(df.product_description)\\n    text_data = X\\n    model = SentenceTransformer('distilbert-base-nli-mean-tokens')\\n    embeddings = model.encode(text_data, show_progress_bar=True)\\n    embed_data = embeddings\\n    X = np.array(embed_data)\\n    return pd.DataFrame(cosine_similarity(X))\\n\\n\\n# Create Recommender \\ndef recommender(search, df, ingred=False, description=False, product_count = 5):\\n    if(ingred):\\n        myItem = df[df.name == search]\\n        myItem.reset_index(drop=True, inplace=True)\\n        P1 = np.array([myItem.X.values, myItem.Y.values]).reshape(1, -1)\\n        cos_sim = []\\n        for i in range(len(df)):\\n            P2 = np.array([df['X'][i], df['Y'][i]]).reshape(-1, 1)\\n            cos_sim.append((np.dot(P1, P2)/(np.linalg.norm(P1)*np.linalg.norm(P2)))[0][0])\\n        \\n        index_recomm = pd.DataFrame(cos_sim, columns=['cosine_sim']).sort_values(by=['cosine_sim'],ascending=False).index.tolist()\\n        products_recomm =  df.loc[index_recomm]\\n                \\n    elif(description):\\n        cos_sim = embed_description(df)\\n        index = df.index[df['name'] == search][0]\\n        index_recomm = cos_sim.loc[index].sort_values(ascending=False).index.tolist()\\n        products_recomm =  df.loc[index_recomm]\\n        \\n    products_recomm = products_recomm[(products_recomm.name != search)]\\n\\n    return products_recomm.head(product_count)\\n\\n\\n\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a6c143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models.ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"codellama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4752e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response_message = llm.invoke(\n",
    "#     \"In bash, how do I list all the text files in the current directory that have been modified in the last month?\"\n",
    "# )\n",
    "\n",
    "# print(response_message.content)\n",
    "# print(response_message.response_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68ac1f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.1.8-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting httpx<0.28.0,>=0.27.0 (from ollama)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7.1)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.4)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.13.0)\n",
      "Requirement already satisfied: exceptiongroup in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.0)\n",
      "Downloading ollama-0.1.8-py3-none-any.whl (9.4 kB)\n",
      "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: httpx, ollama\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.25.2\n",
      "    Uninstalling httpx-0.25.2:\n",
      "      Successfully uninstalled httpx-0.25.2\n",
      "Successfully installed httpx-0.27.0 ollama-0.1.8\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3c12a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/httpcore/_exceptions.py\", line 10, in map_exceptions\n",
      "    yield\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/httpcore/_backends/sync.py\", line 206, in connect_tcp\n",
      "    sock = socket.create_connection(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py\", line 845, in create_connection\n",
      "    raise err\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/socket.py\", line 833, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 61] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/httpx/_transports/default.py\", line 66, in map_httpcore_exceptions\n",
      "    @contextlib.contextmanager\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/httpx/_transports/default.py\", line 228, in handle_request\n",
      "    headers=request.headers.raw,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py\", line 268, in handle_request\n",
      "    raise exc\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py\", line 251, in handle_request\n",
      "    response = connection.handle_request(request)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/httpcore/_sync/connection.py\", line 99, in handle_request\n",
      "    raise exc\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/httpcore/_sync/connection.py\", line 76, in handle_request\n",
      "    stream = self._connect(request)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/httpcore/_sync/connection.py\", line 124, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/httpcore/_backends/sync.py\", line 205, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 61] Connection refused\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/zv/_pgs08m50tl8bhpc54p4w53r0000gn/T/ipykernel_2364/92102866.py\", line 1, in <module>\n",
      "    ollama.generate(model='llama2', prompt='Why is the sky blue?')\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ollama/_client.py\", line 126, in generate\n",
      "    return self._request_stream(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ollama/_client.py\", line 97, in _request_stream\n",
      "    return self._stream(*args, **kwargs) if stream else self._request(*args, **kwargs).json()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ollama/_client.py\", line 68, in _request\n",
      "    response = self._client.request(method, url, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/httpx/_client.py\", line 814, in request\n",
      "    request = self.build_request(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/httpx/_client.py\", line 901, in send\n",
      "    \"\"\"\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/httpx/_client.py\", line 929, in _send_handling_auth\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/httpx/_client.py\", line 966, in _send_handling_redirects\n",
      "    request: Request,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/httpx/_client.py\", line 1002, in _send_single_request\n",
      "    \"\"\"\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/httpx/_transports/default.py\", line 227, in handle_request\n",
      "    ),\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/httpx/_transports/default.py\", line 83, in map_httpcore_exceptions\n",
      "    raise\n",
      "httpx.ConnectError: [Errno 61] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 1997, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1112, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1006, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 859, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 812, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 730, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "ollama.generate(model='llama2', prompt='Why is the sky blue?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "22f5e6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 20 key-value pairs and 363 tensors from /Users/aishwaryagavili/Downloads/codellama-13b-instruct.Q4_K_S.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = codellama_codellama-13b-instruct-hf\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 16384\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 14\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32016]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32016]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32016]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q4_K:  273 tensors\n",
      "llama_model_loader: - type q5_K:    8 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: mismatch in special tokens definition ( 264/32016 vs 259/32016 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32016\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 16384\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 1000000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 16384\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Small\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 6.90 GiB (4.56 BPW) \n",
      "llm_load_print_meta: general.name     = codellama_codellama-13b-instruct-hf\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/41 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  7070.25 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 5024\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  3925.00 MiB\n",
      "llama_new_context_with_model: KV self size  = 3925.00 MiB, K (f16): 1962.50 MiB, V (f16): 1962.50 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   442.32 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1286\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '40', 'llama.context_length': '16384', 'llama.attention.head_count': '40', 'llama.rope.freq_base': '1000000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '14', 'llama.feed_forward_length': '13824', 'llama.embedding_length': '5120', 'llama.block_count': '40', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'codellama_codellama-13b-instruct-hf'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.base import BaseCallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import LlamaCpp\n",
    "\n",
    "llm_path = '/Users/aishwaryagavili/Downloads/codellama-13b-instruct.Q4_K_S.gguf'\n",
    "callback_manager = BaseCallbackManager([StreamingStdOutCallbackHandler])\n",
    "llm=LlamaCpp(\n",
    "    model_path=llm_path,\n",
    "    n_ctx=5000,\n",
    "    n_batch=512,\n",
    "    f16_kv=True,\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "67eca4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# qa = ConversationalRetrievalChain.from_llm(llm,retriever=retriever)\n",
    "# chat_history = []\n",
    "# while(True):\n",
    "#     print(\"Enter a question: \")\n",
    "#     question=input()\n",
    "#     result = qa({\"question\":question,\"chat_history\":chat_history})\n",
    "#     chat_history.append((question,result['answer']))\n",
    "#     print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c35f1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaCpp(callbacks=<langchain_core.callbacks.base.BaseCallbackManager object at 0x14f470f10>, client=<llama_cpp.llama.Llama object at 0x14f827730>, model_path='/Users/aishwaryagavili/Downloads/codellama-13b-instruct.Q4_K_S.gguf', n_ctx=5000, n_batch=512)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e6b9fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "template =\"\"\"\n",
    "[INST]\n",
    "\n",
    "<<SYS>> \n",
    "You are an expert in software engineering. You will use the provided context to answer the user's\n",
    "questions. Read the given context before answering the question and think step by step. If you are\n",
    "unable to answer the question based on the provided context, please inform the user of what context\n",
    "is missing. Do not use any other information for answering the user.\n",
    "<</SYS>>\n",
    "\n",
    "Context: {context}\n",
    "User: {question}\n",
    "    \n",
    "[/INST]\n",
    "\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate(\n",
    "    input_variables= [\"context\", \"question\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "56062823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 5, updating n_results = 5\n"
     ]
    }
   ],
   "source": [
    "question = \"How are embeddings done?\"\n",
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ebfd6504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   19431.83 ms\n",
      "llama_print_timings:      sample time =      29.21 ms /   256 runs   (    0.11 ms per token,  8765.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  125671.03 ms /  2789 tokens (   45.06 ms per token,    22.19 tokens per second)\n",
      "llama_print_timings:        eval time =  311569.69 ms /   255 runs   ( 1221.84 ms per token,     0.82 tokens per second)\n",
      "llama_print_timings:       total time =  438251.73 ms /  3044 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output_text': '\\x0c[LESSON_SECTION_1]\\nAs a developer, I understand that embeddings are done using various machine learning algorithms.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=QA_CHAIN_PROMPT)\n",
    "chain({\"input_documents\": docs,\"question\": question}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eae08f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 20 is greater than number of elements in index 5, updating n_results = 5\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# Prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate(\n",
    "    input_variables= [\"context\", \"question\"],\n",
    "    template=template,\n",
    ")\n",
    "# Docs\n",
    "question = \"How can I initialize a ReAct agent?\"\n",
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0032b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
